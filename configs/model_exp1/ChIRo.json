{
  "layers_dict": {
    "EConv_mlp_hidden_sizes": [
      32
    ],
    "GAT_hidden_node_sizes": [
      64,
      64,
      64
    ],
    "encoder_hidden_sizes_D": [
      32,
      32
    ],
    "encoder_hidden_sizes_phi": [
      32,
      32
    ],
    "encoder_hidden_sizes_c": [
      32,
      32
    ],
    "encoder_hidden_sizes_alpha": [
      32,
      32
    ],
    "encoder_hidden_sizes_sinusoidal_shift": [
      128,
      128
    ],
    "output_mlp_hidden_sizes": [
      128
    ]
  },
  "activation_dict": {
    "encoder_hidden_activation_D": "torch.nn.LeakyReLU(negative_slope=0.01)",
    "encoder_hidden_activation_phi": "torch.nn.LeakyReLU(negative_slope=0.01)",
    "encoder_hidden_activation_c": "torch.nn.LeakyReLU(negative_slope=0.01)",
    "encoder_hidden_activation_alpha": "torch.nn.LeakyReLU(negative_slope=0.01)",
    "encoder_hidden_activation_sinusoidal_shift": "torch.nn.LeakyReLU(negative_slope=0.01)",
    "encoder_output_activation_D": "torch.nn.Identity()",
    "encoder_output_activation_phi": "torch.nn.Identity()",
    "encoder_output_activation_c": "torch.nn.Identity()",
    "encoder_output_activation_alpha": "torch.nn.Identity()",
    "encoder_output_activation_sinusoidal_shift": "torch.nn.Identity()",
    "EConv_mlp_hidden_activation": "torch.nn.LeakyReLU(negative_slope=0.01)",
    "EConv_mlp_output_activation": "torch.nn.Identity()",
    "output_mlp_hidden_activation": "torch.nn.LeakyReLU(negative_slope=0.01)",
    "output_mlp_output_activation": "torch.nn.Identity()"
  },
  "F_z_list": [
    64,
    64,
    64
  ],
  "F_H": 8,
  "F_H_EConv": 8,
  "GAT_N_heads": 8,
  "EConv_bias": true,
  "GAT_bias": true,
  "encoder_biases": true,
  "dropout": 0.0,

  "chiral_message_passing": false,
  "CMP_EConv_MLP_hidden_sizes": [
    32
  ],
  "CMP_GAT_N_layers": 3,
  "CMP_GAT_N_heads": 2,
  "encoder_reduction": "sum",
  "output_concatenation_mode": "both",

  "c_coefficient_normalization": "sigmoid"
}

